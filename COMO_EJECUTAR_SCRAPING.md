# üöÄ C√≥mo Ejecutar el Scraping

## ‚ö†Ô∏è IMPORTANTE: Cambio de Nombre

El archivo **`src/process-csv-causas.js`** fue **renombrado** a **`src/process-causas.js`**.

**‚ùå NO funciona:**
```bash
node src/process-csv-causas.js 5
```

**‚úÖ S√ç funciona:**
```bash
node src/process-causas.js 5
```

---

## üìã Formas de Ejecutar el Scraping

### 1. **Scraping desde CSV (Batch)**
Procesa causas desde el archivo `causa.csv`:

```bash
# Procesar 5 causas
npm run scrape:batch

# O directamente
node src/process-causas.js 5
```

**Par√°metros:**
- Sin par√°metros: Procesa 5 causas por defecto
- Con n√∫mero: `node src/process-causas.js 10` ‚Üí Procesa 10 causas
- Lee desde: `causa.csv` en la ra√≠z del proyecto

---

### 2. **Scraping Masivo (Una Vez)**
Procesa todas las causas del CSV una vez:

```bash
npm run scrape:masivo
```

**Caracter√≠sticas:**
- ‚úÖ Guarda checkpoint para poder continuar si se interrumpe
- ‚úÖ Pausa entre causas (5 segundos)
- ‚úÖ Puede reanudarse desde donde qued√≥

---

### 3. **Scraping Continuo 24/7 (Monitoreo)**
Recorre causas activas peri√≥dicamente buscando movimientos nuevos:

```bash
# Con intervalo por defecto (1 hora)
npm run scrape:monitoreo

# Con intervalo personalizado (30 minutos)
node src/worker-monitoreo-continuo.js --interval 1800000

# Ejecutar una vez (para testing)
node src/worker-monitoreo-continuo.js --once
```

**Caracter√≠sticas:**
- ‚úÖ Se ejecuta 24/7 sin parar
- ‚úÖ Detecta solo movimientos nuevos
- ‚úÖ Actualiza BD solo cuando hay cambios

---

### 4. **Scraping por Endpoint (API)**
Ejecuta scraping v√≠a HTTP:

```bash
# Iniciar servidor API
npm run api:start

# Llamar endpoint
curl -X POST http://localhost:3000/api/scraping/ejecutar \
  -H "Content-Type: application/json" \
  -d '{
    "rit": "C-3030-2017",
    "competencia": "3",
    "corte": "90",
    "tribunal": "61",
    "tipoCausa": "C"
  }'
```

---

## üîç Verificar Archivos Disponibles

Para ver qu√© archivos de scraping existen:

```bash
ls -la src/process*.js
ls -la src/worker*.js
ls -la src/scraping*.js
```

**Archivos principales:**
- ‚úÖ `src/process-causas.js` - Motor principal (antes `process-csv-causas.js`)
- ‚úÖ `src/scraping_masivo.js` - Scraping masivo desde CSV
- ‚úÖ `src/worker-monitoreo-continuo.js` - Monitoreo 24/7
- ‚úÖ `src/worker_cola_scraping.js` - Worker de cola
- ‚úÖ `src/worker-eventos.js` - Worker de eventos ERP

---

## üìù Ejemplos de Uso

### Ejemplo 1: Procesar 10 causas desde CSV
```bash
node src/process-causas.js 10
```

### Ejemplo 2: Scraping masivo completo
```bash
npm run scrape:masivo
```

### Ejemplo 3: Monitoreo continuo (cada 30 minutos)
```bash
node src/worker-monitoreo-continuo.js --interval 1800000
```

### Ejemplo 4: Probar monitoreo una vez
```bash
node src/worker-monitoreo-continuo.js --once
```

---

## ‚ö†Ô∏è Errores Comunes

### Error: "Cannot find module 'process-csv-causas.js'"
**Causa**: Est√°s usando el nombre antiguo del archivo.

**Soluci√≥n**: Usa `process-causas.js` en lugar de `process-csv-causas.js`:
```bash
# ‚ùå Incorrecto
node src/process-csv-causas.js 5

# ‚úÖ Correcto
node src/process-causas.js 5
```

### Error: "Access denied for user 'root'"
**Causa**: Credenciales de BD incorrectas o BD no est√° corriendo.

**Soluci√≥n**: 
1. Verifica que Docker est√© corriendo: `docker ps | grep pjud-mariadb-55`
2. Verifica tu `.env` tiene las credenciales correctas
3. Verifica el puerto (deber√≠a ser 3307, no 3306)

---

## üìö M√°s Informaci√≥n

- Ver `CASOS_USO_SCRAPING.md` para los 3 casos de uso principales
- Ver `docs/scraping-standard.md` para el est√°ndar de scraping
- Ver `package.json` para todos los scripts disponibles
