# ğŸš€ GuÃ­a: Scraping Masivo de Causas

Esta guÃ­a te explica cÃ³mo ejecutar el scraping masivo de mÃºltiples causas desde el archivo CSV.

## ğŸ“‹ Requisitos Previos

1. **Archivo CSV de causas**: AsegÃºrate de tener `causa.csv` o `causa_validas.csv` en la raÃ­z del proyecto
2. **Variables de entorno**: Archivo `.env` configurado con `OJV_URL`
3. **Dependencias instaladas**: `npm install` ya ejecutado
4. **Navegadores Playwright**: `npx playwright install chromium`

---

## ğŸ¯ Formas de Ejecutar

### OpciÃ³n 1: Usando npm script (Recomendado)

```bash
# Procesar 10 causas (nÃºmero por defecto)
npm run scrape:batch

# Procesar 50 causas
npm run scrape:batch 50

# Procesar 100 causas
npm run scrape:batch 100

# Procesar TODAS las causas del CSV (0 = todas)
npm run scrape:batch 0
```

### OpciÃ³n 2: Directo con Node.js

```bash
# Procesar 10 causas (por defecto)
node src/process-csv-causas.js

# Procesar 50 causas
node src/process-csv-causas.js 50

# Procesar 100 causas
node src/process-csv-causas.js 100

# Procesar TODAS las causas (0 = todas)
node src/process-csv-causas.js 0
```

---

## ğŸ”„ Reanudar desde Checkpoint

Si el scraping se detuvo (por error, bloqueo, etc.), puedes reanudar desde donde se quedÃ³:

```bash
# Reanudar desde el Ãºltimo checkpoint
node src/process-csv-causas.js 0 --resume

# O con la forma corta
node src/process-csv-causas.js 0 -r
```

**Nota**: El checkpoint guarda solo las causas exitosas, asÃ­ que las que fallaron se reintentarÃ¡n automÃ¡ticamente.

---

## ğŸ“Š Ejemplos de Uso

### Ejemplo 1: Prueba PequeÃ±a (5 causas)
```bash
node src/process-csv-causas.js 5
```
Ideal para probar que todo funciona correctamente antes de procesar grandes cantidades.

### Ejemplo 2: Lote Mediano (50 causas)
```bash
node src/process-csv-causas.js 50
```
Procesa 50 causas con delays entre cada una para evitar bloqueos.

### Ejemplo 3: Lote Grande (200 causas)
```bash
node src/process-csv-causas.js 200
```
Procesa hasta 200 causas. El script verificarÃ¡ bloqueos despuÃ©s de cada causa.

### Ejemplo 4: Todas las Causas
```bash
node src/process-csv-causas.js 0
```
Procesa **todas** las causas vÃ¡lidas del CSV. âš ï¸ Esto puede tardar horas o dÃ­as.

---

## âš™ï¸ ConfiguraciÃ³n y Comportamiento

### Archivo CSV Requerido

El script lee desde `causa.csv` en la raÃ­z del proyecto. Debe tener estas columnas:
- `causa_id`: ID de la causa
- `rit`: RIT de la causa (ej: "C-13786-2018")
- `competencia`: ID de competencia (ej: "3" para Civil)
- `tribunal`: ID de tribunal
- `tipo_causa`: Tipo de causa (ej: "C")

### Filtrado AutomÃ¡tico

El script automÃ¡ticamente:
- âœ… Solo procesa causas con RIT vÃ¡lido
- âœ… Filtra causas duplicadas por `causa_id`
- âœ… Asume competencia "3" (Civil) si no estÃ¡ especificada

### Delays entre Causas

Para evitar bloqueos, el script:
- â³ Espera **5-15 segundos** entre cada causa
- â³ Espera **3-5 segundos** adicionales si hubo un error en la causa anterior
- â³ Verifica CAPTCHA/bloqueo despuÃ©s de cada causa

### LÃ­mite Diario

Por defecto hay un lÃ­mite de **150 causas por dÃ­a** para evitar bloqueos. Puedes modificarlo en:
- Archivo: `src/daily_count.json`
- Variable: `DEFAULT_DAILY_LIMIT` en `src/process-csv-causas.js`

---

## ğŸ“ Archivos Generados

### Durante la EjecuciÃ³n

```
src/outputs/
â”œâ”€â”€ resultado_C_13786_2018.json     # JSON con movimientos
â”œâ”€â”€ resultado_C_13786_2018.csv      # CSV con movimientos
â”œâ”€â”€ movimientos_C_13786_2018.json   # JSON estructurado
â”œâ”€â”€ C_13786_2018_doc_1.pdf          # PDFs descargados
â”œâ”€â”€ C_13786_2018_doc_2.pdf
â””â”€â”€ ...
```

### Checkpoints y Logs

```
src/logs/
â”œâ”€â”€ checkpoints/
â”‚   â””â”€â”€ last_checkpoint.json        # Estado del scraping
â”œâ”€â”€ causas_pendientes_TIMESTAMP.json # Causas no procesadas
â”œâ”€â”€ bloqueo_causa_X_TIMESTAMP.png   # Screenshot si hay bloqueo
â””â”€â”€ daily_count.json                # Contador diario
```

---

## ğŸš¨ Manejo de Bloqueos

Si el script detecta un bloqueo/CAPTCHA:

1. **Se detiene inmediatamente** (NO reintenta automÃ¡ticamente)
2. **Muestra mensaje claro** con instrucciones
3. **Guarda checkpoint** con el progreso actual
4. **Guarda causas pendientes** para continuar despuÃ©s
5. **Guarda screenshot** para diagnÃ³stico

### QuÃ© Hacer Si Hay Bloqueo

```
ğŸš¨ ============================================
ğŸš¨ BLOQUEO/CAPTCHA DETECTADO - DETENIENDO
ğŸš¨ ============================================

ğŸ“ ACCIÃ“N REQUERIDA:
   1. Espera 30-60 minutos antes de reintentar
   2. Considera usar una VPN o cambiar tu IP
   3. Reduce la velocidad de scraping si continÃºas
   4. Verifica manualmente en el navegador si el bloqueo persiste

â¸ï¸  El proceso se ha detenido para evitar empeorar el bloqueo.
```

**Para continuar despuÃ©s:**
```bash
# Espera 30-60 minutos y luego:
node src/process-csv-causas.js 0 --resume
```

---

## ğŸ“Š Monitoreo del Progreso

### Durante la EjecuciÃ³n

El script muestra informaciÃ³n en tiempo real:
```
ğŸš€ Iniciando scraping masivo...
ğŸ“Š Causas vÃ¡lidas: 3222
ğŸ“‹ Se procesarÃ¡n 50 causas del CSV.

âœ… Procesando causa 1/50: C-13786-2018
   âœ… Causa procesada exitosamente
   â³ Esperando 8s antes de la siguiente causa (anti-bloqueo)...

âœ… Procesando causa 2/50: C-23607-2015
   âœ… Causa procesada exitosamente
   â³ Esperando 12s antes de la siguiente causa (anti-bloqueo)...

...

ğŸ“Š Resumen final:
   âœ… Exitosas: 45
   âŒ Fallidas: 5
   â±ï¸  Tiempo total: 15 minutos
```

### Verificar Progreso Guardado

```bash
# Ver el checkpoint actual
cat src/logs/checkpoints/last_checkpoint.json

# Ver contador diario
cat src/logs/daily_count.json

# Ver causas pendientes (si hubo bloqueo)
cat src/logs/causas_pendientes_*.json
```

---

## ğŸ”§ Opciones Avanzadas

### Procesar Solo Causas con Tribunal

Si quieres procesar solo causas que tienen tribunal especificado (mayor tasa de Ã©xito):

Edita `src/process-csv-causas.js` lÃ­nea ~149:
```javascript
const requireTribunal = true; // Cambiar a true
```

### Aumentar Delays

Para reducir riesgo de bloqueo, aumenta los delays en `src/process-csv-causas.js`:

```javascript
// LÃ­nea ~398: Delay entre causas
const delay = 10000 + Math.random() * 20000; // Cambiar a 10-30 segundos
```

### Modo Headless

Por defecto el navegador es visible. Para ocultarlo (mÃ¡s rÃ¡pido pero menos debugging):

Edita `src/browser.js` o pasa `headless: true` a `startBrowser()`.

---

## ğŸ“ˆ Ejemplo de SesiÃ³n Completa

```bash
# 1. Primera ejecuciÃ³n: 50 causas
node src/process-csv-causas.js 50

# 2. Si se bloquea, espera 30-60 minutos y reanuda:
node src/process-csv-causas.js 0 --resume

# 3. Continuar con mÃ¡s causas:
node src/process-csv-causas.js 100

# 4. Verificar resultados:
ls -lh src/outputs/*.json | wc -l  # Contar causas procesadas
```

---

## âš ï¸ Recomendaciones Importantes

### Para Evitar Bloqueos:

1. **Empieza con lotes pequeÃ±os** (10-20 causas) para probar
2. **Aumenta gradualmente** (50, 100, 200)
3. **Ejecuta en horarios de menor trÃ¡fico** (madrugada)
4. **Respeta el lÃ­mite diario** de 150 causas
5. **Monitorea los logs** para detectar bloqueos temprano

### Si Ya EstÃ¡s Bloqueado:

1. **Espera 30-60 minutos** antes de reintentar
2. **Cambia tu IP** usando VPN o proxy
3. **Reduce aÃºn mÃ¡s la velocidad** (aumenta delays)
4. **Procesa menos causas por sesiÃ³n** (10-20 mÃ¡ximo)

---

## ğŸ¯ Resumen de Comandos RÃ¡pidos

```bash
# Procesar 10 causas (prueba)
node src/process-csv-causas.js 10

# Procesar 50 causas (lote mediano)
node src/process-csv-causas.js 50

# Procesar todas las causas
node src/process-csv-causas.js 0

# Reanudar desde checkpoint
node src/process-csv-causas.js 0 --resume

# Usar script npm
npm run scrape:batch 50
```

---

## ğŸ“ SoluciÃ³n de Problemas

### Error: "No se encontrÃ³ el archivo: causa.csv"

```bash
# Verifica que el archivo existe
ls -la causa.csv

# Si no existe, usa causa_validas.csv
# Edita src/read-csv.js lÃ­nea 7 para cambiar el nombre
```

### Error: "Cannot find module"

```bash
npm install
npx playwright install chromium
```

### El proceso se detiene sin razÃ³n aparente

```bash
# Verifica logs
tail -f src/logs/checkpoints/last_checkpoint.json

# Verifica si hay bloqueo
ls -la src/logs/bloqueo_*.png
```

### Quiero empezar desde cero

```bash
# Elimina el checkpoint
rm src/logs/checkpoints/last_checkpoint.json

# Elimina contador diario (opcional)
rm src/logs/daily_count.json
```

---

**Â¡Listo! Ya puedes ejecutar el scraping masivo.** ğŸš€
